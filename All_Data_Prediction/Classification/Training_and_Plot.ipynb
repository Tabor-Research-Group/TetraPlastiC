{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2597a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Function to convert a string expression into a pandas Series operation\n",
    "def string_to_pandas_series_ops(string, variable):\n",
    "    for variable_name, series in variable.items():\n",
    "        exec(f\"{variable_name} = series\")\n",
    "    return eval(re.sub(r\"[a-zA-Z]+\\d+\", lambda match: f\"{match.group()} \", string))\n",
    "\n",
    "Y_pred_score = []\n",
    "Selected_features = []\n",
    "\n",
    "# Loop over 100 datasets\n",
    "for i in range(100):\n",
    "    # Load training and testing data\n",
    "    df_train = pd.read_csv(f'{i}/train.dat', sep='\\t')\n",
    "    df_test = pd.read_csv(f'{i}/test.dat', sep='\\t')\n",
    "    \n",
    "    # Extract class labels from dataset\n",
    "    Class_test = [int(x.split('group')[-1]) for x in df_test.iloc[:, 0]]\n",
    "    Class = [int(x.split('group')[-1]) for x in df_train.iloc[:, 0]]\n",
    "    \n",
    "    # Extract feature names and store references\n",
    "    variable_names = [f\"feature{l}\" for l in range(1, df_train.shape[1])]\n",
    "    variable_ref = {name: df_train[name] for name in variable_names}\n",
    "    variable_test = {name: df_test[name] for name in variable_names}\n",
    "    \n",
    "    # Read model and feature space files\n",
    "    with open(f'{i}/models/top0100_D002', 'r') as model_file, \\\n",
    "         open(f'{i}/SIS_subspaces/Uspace.expressions', 'r') as feature_space, \\\n",
    "         open(f'./feature_name_{i}', \"rb\") as fp:\n",
    "        lines_model = model_file.readlines()\n",
    "        lines_feature = feature_space.readlines()\n",
    "        feature_name = pickle.load(fp)\n",
    "    \n",
    "    # Process 100 models per dataset\n",
    "    for j in range(100):\n",
    "        ID1, ID2 = map(int, [lines_model[j+1].split()[4], lines_model[j+1].split()[5].replace(')', '')])\n",
    "        Feature1_string, Feature2_string = lines_feature[ID1-1].split()[0], lines_feature[ID2-1].split()[0]\n",
    "        \n",
    "        # Convert feature strings to pandas Series\n",
    "        feature1, feature2 = string_to_pandas_series_ops(Feature1_string, variable_ref), string_to_pandas_series_ops(Feature2_string, variable_ref)\n",
    "        feature1_test, feature2_test = string_to_pandas_series_ops(Feature1_string, variable_test), string_to_pandas_series_ops(Feature2_string, variable_test)\n",
    "        \n",
    "        # Extract and store selected features\n",
    "        Selected_features.extend([feature_name[int(k)-1] for k in re.findall(r'feature(\\d+)', Feature1_string)])\n",
    "        Selected_features.extend([feature_name[int(k)-1] for k in re.findall(r'feature(\\d+)', Feature2_string)])\n",
    "        \n",
    "        # Prepare feature matrices\n",
    "        X, X_test = np.column_stack((feature1, feature2)), np.column_stack((feature1_test, feature2_test))\n",
    "        Y, Y_test = np.array(Class), np.array(Class_test)\n",
    "        \n",
    "        # Hyperparameter tuning for best SVM model\n",
    "        best_C, best_G, best_score = 0, 0, 0\n",
    "        for c in [0.1, 1, 10, 100, 1000]:\n",
    "            for g in [0.001, 0.01, 0.1, 1, 10]:\n",
    "                svf_rbf = svm.SVC(C=c, gamma=g, probability=True)\n",
    "                svf_rbf.fit(X, Y)\n",
    "                if svf_rbf.score(X, Y) > best_score:\n",
    "                    best_C, best_G, best_score = c, g, svf_rbf.score(X, Y)\n",
    "        \n",
    "        # Train best model and record scores\n",
    "        svf_rbf = svm.SVC(C=best_C, gamma=best_G, probability=True)\n",
    "        svf_rbf.fit(X, Y)\n",
    "        Y_pred_score.extend([svf_rbf.score(X_test, Y_test)] * len(re.findall(r'feature(\\d+)', Feature1_string) + re.findall(r'feature(\\d+)', Feature2_string)))\n",
    "    \n",
    "# Analyze selected feature frequency\n",
    "selected_feature, feature_counts = np.unique(Selected_features, return_counts=True)\n",
    "\n",
    "# Define modified feature labels for improved visualization\n",
    "selected_feature_modified = np.array([r'$\\sigma_{ang}$', '$\\mu_{ang}$', '$\\it{Br}$', '$\\it{C_4H_9}$', '$\\it{CH(CH_3)OH)}$', '$\\it{CH_2NH_2}$',\n",
    "       '$\\it{CH_2Br}$', '$\\it{CH_2Cl}$', '$\\it{CH_2F}$', '$\\it{CH_2NH_2}$', '$\\it{CHClOH}$','$\\it{CHFOH}$', '$\\it{CHO}$',\n",
    "        '$\\it{COCl}$', '$\\it{CONH_2}$','$\\it{COOH}$', 'Center of Mass', '$\\it{Cl}$',\n",
    "       '$E_{CT}$', '$E_{dispersion}$', '$\\it{F}$',\n",
    "       'Interaction Energy', 'Maxacc', '$\\it{NH_2}$', '$\\it{NO_2}$', '$\\it{OH}$', '$\\mu_R$',\n",
    "       '$\\sigma_R$', '$\\it{SH}$', 'Volume', '$\\mu_{dist}$'])\n",
    "\n",
    "# Prepare stacked bar plot\n",
    "score_stacking = []\n",
    "for i in selected_feature:\n",
    "    tmp = np.histogram(np.array(Y_pred_score)[np.where(np.array(Selected_features) == i)[0]], bins=[-np.inf, 0, 0.2, 0.4, 0.6, 0.8, np.inf])[0]\n",
    "    score_stacking.append(tmp)\n",
    "    \n",
    "# Normalize and plot stacked bar chart\n",
    "all_number = np.sum(score_stacking)\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['score < 0.0', '0.2 <= score < 0.0', '0.4 <= score < 0.2', '0.6 <= score < 0.4',\n",
    "          '0.8 <= score < 0.6', '1.0 <= score < 0.8']\n",
    "width = 0.5\n",
    "color_codes = ['#264653', '#2a9d8f', '#8ab17d', '#e9c46a', '#f4a261', '#8c510a']\n",
    "\n",
    "for i in range(6):\n",
    "    bottom = np.sum(np.array(score_stacking)[:, :i], axis=1) / all_number\n",
    "    ax.bar(selected_feature_modified, np.array(score_stacking)[:, i] / all_number, width, label=labels[i], bottom=bottom, color=color_codes[i])\n",
    "\n",
    "plt.xticks(rotation='90')\n",
    "plt.xlabel('Descriptors', fontsize=32)\n",
    "plt.ylabel('Ratio in the SISSO Model Ensemble', fontsize=32)\n",
    "plt.xticks(fontsize=34)\n",
    "plt.yticks(fontsize=32)\n",
    "ax.legend(fontsize=24)\n",
    "plt.title('Selected Descriptors Ratio from Classification', fontsize=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
